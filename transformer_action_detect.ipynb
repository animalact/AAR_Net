{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformer-action-detect",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biSvv314uNsk"
      },
      "source": [
        "#**Library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je2IARt0iqPk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed2438ca-ec95-402d-bc17-8bad32895b14"
      },
      "source": [
        "from PIL import Image\n",
        "from PIL import JpegImagePlugin\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import easydict\n",
        "import math\n",
        "import torch\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import sys\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA2pObxzAAox"
      },
      "source": [
        "!tar -xvf '/content/drive/Shareddrives/예림 하이/label_yerim.tar'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2RVt7JC3Nv3"
      },
      "source": [
        "# getAngle\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8EROZr9i5HT"
      },
      "source": [
        "def getAngle(start, mid, end):\n",
        "        \"\"\"\n",
        "        Calculate the angle between start and end\n",
        "        :param start: start point [x, y]\n",
        "        :param end: mid point [x, y]\n",
        "        :param end: end point [x, y]\n",
        "        :return: the clockwise angle from start to end\n",
        "        \"\"\"\n",
        "        v1 = np.array([0,0])\n",
        "        v2 = np.array([0,0])\n",
        "\n",
        "        v1[0] = (start[0]-mid[0])\n",
        "        v1[1] = (start[1]-mid[1])\n",
        "\n",
        "        v2[0] = (end[0]-mid[0])\n",
        "        v2[1] = (end[1]-mid[1])\n",
        "       #  angle = np.arccos((v1[0]*v2[0]+v1[1]*v2[1])/(math.sqrt(v1[0]*v1[0] + v1[1]*v1[1])*math.sqrt(v2[0]*v2[0] + v2[1]*v2[1]))*math.pi/180)\n",
        "\n",
        "        #a = (v1[0]*v2[0]+v1[1]*v2[1])\n",
        "        k = v1[0]*v1[0] + v1[1]*v1[1]\n",
        "        j = v2[0]*v2[0] + v2[1]*v2[1]\n",
        "        if k==0 or j==0 :\n",
        "          angle = 0\n",
        "        else:\n",
        "          b = math.sqrt(k)*math.sqrt(j)\n",
        "          c = np.inner(v1,v2)/b\n",
        "          angle = 0\n",
        "          if c <= 1 and c >=-1 :\n",
        "            angle = np.arccos(c)\n",
        "        #  print(c)\n",
        "        #  print('각도:')\n",
        "       #   print(angle*180/math.pi)\n",
        "        \n",
        "        return angle*180/math.pi\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cju52aU6sDh-",
        "outputId": "acff5101-dbfc-4989-dbc6-86d76776724a"
      },
      "source": [
        "getAngle([1,0],[0,0],[1,1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45.00000000000001"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dloa_ei0sY0y",
        "outputId": "91aca196-9ea3-464d-a126-14324da0187a"
      },
      "source": [
        "getAngle([0,0], [0,0],[0,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-KRvgj8skiA",
        "outputId": "b9bcd68d-0e88-4ab9-923f-d7b69c9ec15b"
      },
      "source": [
        "getAngle([1,1.717], [0,0],[1,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45.00000000000001"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aYCiCkaeDTf"
      },
      "source": [
        "# pose= np.load('label_yerim/label_9/cat-sitdown-098036.npy')\n",
        "# #print(type(data))\n",
        "# #print(data.shape)\n",
        "# #print(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3CfwiVHcDjv"
      },
      "source": [
        "# df = pd.read_csv('/content/label_yerim/label_8.csv')\n",
        "\n",
        "# lab = df['action']\n",
        "# filename = df['filename']\n",
        "\n",
        "# label = lab.values.tolist()\n",
        "# file_list = filename.values.tolist()\n",
        "\n",
        "# print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMV4TzDBB5XC"
      },
      "source": [
        "act_dict = {\n",
        "    '배를 보여주는 동작':6,\n",
        "    '좌우로 뒹구는 동작':4,\n",
        "    '좌우로 뒹굴음':4, \n",
        "    '허리를 아치로 세우는 동작':9,\n",
        "    '그루밍하는 동작':3,\n",
        "    '꼬리를 흔드는 동작':7,\n",
        "    '그루밍함':3,\n",
        "    '배를 보임':6,\n",
        "    '걷거나 뜀 ':12,\n",
        "    '옆으로 누워 있음':10,\n",
        "    '꼬리를 흔든다':7, \n",
        "    '걷거나 달리는 동작':12,\n",
        "    '납작 엎드림':1,\n",
        "    '걷거나 뛰는 동작':12,\n",
        "    '앞발로 꾹꾹 누름':8,\n",
        "    '발을 숨기고 웅크리고 앉는 동작':2,\n",
        "    '납작 엎드리는 동작':1,\n",
        "    '허리를 아치로 세움':9, \n",
        "    '배를 보이는 동작':6,\n",
        "    '머리를 들이대는 동작':5, \n",
        "    '팔을 뻗어 휘적거림':11,\n",
        "    '앞발로 꾹꾹 누르는 동작':8,\n",
        "    '옆으로 눕는 동작':10, \n",
        "    '앞발을 뻗어 휘적거리는 동작':11,\n",
        "    '머리를 들이댐':5, \n",
        "    '발을 숨기고 웅크리고 앉음':2\n",
        "}\n",
        "def createLabel(label):\n",
        "    label = int(act_dict[label]) -1\n",
        "    return label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQaIqphJFFyE",
        "outputId": "e56ff7e9-aa23-428b-aa4e-70a71ac85077"
      },
      "source": [
        "print(createLabel('발을 숨기고 웅크리고 앉음'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlMJQjgBj8n5"
      },
      "source": [
        "#**dataset.py**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-HCVTPHj8Fs"
      },
      "source": [
        "class trainDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        train_dir_list = ['label_7', 'label_8', 'label_9']\n",
        "        label_dir_list = ['label_7.csv', 'label_8.csv', 'label_9.csv']\n",
        "        data_path = './label_yerim'\n",
        "\n",
        "        video_list = []\n",
        "        label = []\n",
        "\n",
        "        for dir_idx in label_dir_list:\n",
        "            df = pd.read_csv(os.path.join(data_path, dir_idx))\n",
        "            lab = df['action']\n",
        "            filename = df['filename']\n",
        "\n",
        "            label_ = lab.values.tolist()\n",
        "            label_ = list(map(lambda x: createLabel(x), label_))\n",
        "            \n",
        "            train_videos_ = filename.values.tolist()\n",
        "            video_list.extend(train_videos_)\n",
        "            label.extend(label_)\n",
        "        # 여기까지가 csv파일 읽어오고, label이랑 filename받아오기(사실 한번에 해도 될거같은데..ㅜㅜㅅ ..편하게 함수쓰고 하드코딩 할래요오)\n",
        "\n",
        "        train_videos = []\n",
        "        for dir_idx in train_dir_list:\n",
        "            path = os.path.join(data_path, dir_idx)\n",
        "            for root, _, fnames in sorted(os.walk(path)):\n",
        "                for fname in fnames:\n",
        "                    file_name = fname.split('.npy')\n",
        "                    if file_name[0] in video_list:\n",
        "                        train_videos.append(os.path.join(path, fname))\n",
        "\n",
        "        self.file_list = train_videos\n",
        "        self.label_list = label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      video_data = np.load(self.file_list[idx])\n",
        "      angle_list = []\n",
        "      angle_set = [2, 26, 28]\n",
        "      s, m ,f = angle_set[0], angle_set[1] , angle_set[2]\n",
        "\n",
        "      '''\n",
        "      코 머리 입 입끝 목 앞우관절 앞좌관절 앞우발끝 앞좌발끝 뒤우관절 뒤좌관절 뒤우발끝 뒤좌발끝 꼬리시작 꼬리끝\n",
        "      0   2   4   6   8   10      12        14          16      18      20      22      24    26          28\n",
        "      다리각도 정도랑/ 꼬리/ 머리 목 다리/\n",
        "      '''\n",
        "\n",
        "      for i in range(0, 30):\n",
        "          start_point = list()\n",
        "          mid_point = list()\n",
        "          end_point = list()\n",
        "          if video_data[i][s] != 0:\n",
        "              start_point.append(video_data[i][s])\n",
        "              start_point.append(video_data[i][s+1])\n",
        "          else:\n",
        "              if len(angle_list) == 0:\n",
        "                  angle_list.append(0)\n",
        "              else :\n",
        "                angle_list.append(angle_list[-1])\n",
        "\n",
        "              continue;\n",
        "           ####   \n",
        "          if video_data[i][m] != 0:\n",
        "              mid_point.append(video_data[i][m])\n",
        "              mid_point.append(video_data[i][m+1])\n",
        "          else:\n",
        "              if len(angle_list) == 0:\n",
        "                  angle_list.append(0)\n",
        "              else :\n",
        "                angle_list.append(angle_list[-1])\n",
        "                      \n",
        "              continue;\n",
        "          #####    \n",
        "          if video_data[i][f] != 0:\n",
        "              end_point.append(video_data[i][f])\n",
        "              end_point.append(video_data[i][f+1])\n",
        "          else:\n",
        "              if len(angle_list) == 0:\n",
        "                  angle_list.append(0)\n",
        "              else :\n",
        "                angle_list.append(angle_list[-1])                       \n",
        "              continue;\n",
        "          ######    \n",
        "          angle = getAngle(start_point, mid_point, end_point)\n",
        "          angle_list.append(angle)\n",
        "        \n",
        "      label = self.label_list[idx]\n",
        "      item = (angle_list, label)\n",
        "      print(item)\n",
        "      return item"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "badmkOq8_tyb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHuSGIpbnXt4"
      },
      "source": [
        "#**model.py**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkHwZAhAnUTy"
      },
      "source": [
        "class TransformerModel(nn.Module):\n",
        "  def __init__(self, input_size, nhead, hidden_size, n_layers, dropout=0.1):\n",
        "    super(TransformerModel, self).__init__()\n",
        "\n",
        "\n",
        "    self.model_type = 'Transformer'\n",
        "\n",
        "    self.sequence_length = 30\n",
        "    self.input_size = input_size\n",
        "\n",
        "  ### 인코더\n",
        "    encoder_layers = nn.TransformerEncoderLayer(\n",
        "        d_model=input_size, nhead=nhead, dim_feedforward=hidden_size, dropout=dropout, activation='relu', batch_first=True\n",
        "    )\n",
        "\n",
        "\n",
        "    self.transformer_encoder = nn.TransformerEncoder(encoder_layer=encoder_layers, num_layers=n_layers)\n",
        "\n",
        "##디코더\n",
        "    self.customed_decoder = nn.Sequential(\n",
        "        nn.Linear(30, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 12)\n",
        "    )\n",
        "\n",
        "  def forward(self, angle_seq):\n",
        "  #  print(angle_seq)\n",
        "    features= angle_seq.float()\n",
        "    features = torch.unsqueeze(angle_seq, axis=1)\n",
        "\n",
        "    output = self.transformer_encoder(features)\n",
        "\n",
        "    output = torch.squeeze(output, axis=1)\n",
        " #   print(output.shape)\n",
        "    output = self.customed_decoder(output)\n",
        "    \n",
        "#    print(output)\n",
        "\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fFQubqKtM0n"
      },
      "source": [
        "#**train valid test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ski8povUsw5h"
      },
      "source": [
        "def train(dataloader, epoch):\n",
        "    print('[Epoch %d]' % (epoch+1))\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss() \n",
        "    running_loss = 0.0\n",
        "\n",
        "    start_time = time.time()\n",
        "    for batch_idx, samples in enumerate(dataloader):\n",
        "        # le = preprocessing.LabelEncoder()\n",
        "        \n",
        "        # labels = le.fit_transform(samples[1])\n",
        "        labels = samples[1]\n",
        "        labels = torch.tensor(labels)\n",
        "\n",
        "        angle_list = torch.stack(samples[0], dim=1)\n",
        "\n",
        "\n",
        "        angle_list, labels = angle_list.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad() \n",
        "        # forward + backward + optimize\n",
        "        outputs = net(angle_list.float())\n",
        "        loss = criterion(outputs, labels) \n",
        "      #  print(outputs, labels)\n",
        "      #  print(loss)\n",
        "        if not torch.isfinite(loss):\n",
        "          print('WARNING: non-finite loss, ending training!')\n",
        "          exit(1)\n",
        "\n",
        "        loss.backward() \n",
        "        optimizer.step() \n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if batch_idx % args.loss_interval == (args.loss_interval-1):\n",
        "            elapsed = time.time() - start_time\n",
        "            print('[%d, %5d] loss: %.6f in %.3f seconds' %\n",
        "                  (epoch + 1, batch_idx + 1, running_loss / args.loss_interval, elapsed))\n",
        "            \n",
        "            running_loss = 0.0\n",
        "            start_time = time.time()\n",
        "\n",
        "        if args.split_training:\n",
        "            if batch_idx > 10*args.loss_interval:\n",
        "                break\n",
        "    return running_loss / args.loss_interval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GPXdzGK3nMF"
      },
      "source": [
        "def valid(dataloader, epoch):\n",
        "    print('**Validation**')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    valid_loss = 0.0\n",
        "\n",
        "    classes = (1,2,3,4,5,6,7,8,9,10,11,12)\n",
        "    #,13,14,15,16,17,18,19,20,21,22,23,24,25, 26)\n",
        "    class_correct = list(0. for i in range(12))\n",
        "    class_total = list(0. for i in range(12))\n",
        "    class_acc = list(0. for i in range(12))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for samples in dataloader:\n",
        "            # le = preprocessing.LabelEncoder()\n",
        "\n",
        "            # labels = le.fit_transform(samples[1])\n",
        "            labels = samples[1]\n",
        "            labels = torch.tensor(labels)\n",
        "\n",
        "            angle_list = torch.stack(samples[0], dim=1)\n",
        "\n",
        "            angle_list, labels = angle_list.to(device), labels.to(device)\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(angle_list.float())\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # print statistics\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "     #       print(\"pred\")\n",
        "     #       print(predicted)\n",
        "    #        raise ValueError\n",
        "            c = (predicted == labels).squeeze()\n",
        "   #         print(c)\n",
        "   #         print(c.shape)\n",
        "            for i in range(min(len(labels), args.batch_size)):\n",
        "                label = labels[i]\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "\n",
        "        hap = 0\n",
        "        for i in range(12):\n",
        "            if class_total[i] == 0:\n",
        "                continue;\n",
        "            class_acc[i] = 100 * class_correct[i] / class_total[i]\n",
        "            print('Accuracy of %5s : %.2f %%' % (classes[i], class_acc[i]))\n",
        "            hap += class_acc[i]\n",
        "\n",
        "        valid_loss = valid_loss / len(dataloader)\n",
        "        total_acc = hap / 26\n",
        "        print('Accuracy of %5s : %.2f %%' % ('total', total_acc))\n",
        "        print('Validation Loss: %.6f' % valid_loss)\n",
        "\n",
        "      #  calculate valid best\n",
        "        if total_acc > valid_best['total_acc']:\n",
        "            valid_best['total_acc'] = total_acc\n",
        "            valid_best['epoch'] = epoch + 1\n",
        "\n",
        "            # save model\n",
        "         #   os.makedirs('/content/drive/Shareddrives/예림하이/model', exist_ok=True)\n",
        "            torch.save(net.state_dict(), '/content/drive/Shareddrives/예림 하이/model/transformer-action-best-detect.pth')\n",
        "\n",
        "    return valid_loss, total_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDlKTRbJuGoe"
      },
      "source": [
        "#**<main**>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj8Dv3gebK7m"
      },
      "source": [
        "import easydict\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "args = easydict.EasyDict({\n",
        "        \"batch_size\": 8,\n",
        "        \"epoch\": 50,\n",
        "        \"loss_interval\": 500,\n",
        "        \"split_training\": False,\n",
        "        \"data_path\": '/content/label_yerim',\n",
        "        \"model_name\": 'transformer-action-detect.pth',\n",
        "        \"model_path\": '/content/drive/Shareddrives/예림하이/model'})\n",
        "\n",
        "dataset = trainDataset(args.data_path)\n",
        "train_dataset, valid_dataset = train_test_split(dataset,  test_size=0.2, shuffle=True, random_state=34)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mylHlcMFIJOA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agol-zZDs9ds"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    \n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model_save_path = os.path.join(args.model_path, args.model_name)\n",
        "\n",
        "\n",
        "    input_size = 30\n",
        "    nhead = 2\n",
        "    hidden_size = 128\n",
        "    n_layers = 4\n",
        "    dropout = 0.1\n",
        "\n",
        "    net = TransformerModel(input_size, nhead, hidden_size, n_layers, dropout)\n",
        "    # net.load_state_dict(torch.load(model_save_path)) \n",
        "    net.to(device)\n",
        "    net = net.float()\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=0.00001, momentum=0.9, weight_decay=0.0005)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
        "    valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=args.batch_size)\n",
        "\n",
        "    valid_best = dict(epoch=0, total_acc=0)\n",
        "\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    valid_accuracy = []\n",
        "\n",
        "    for epoch in range(0, args.epoch):\n",
        "        epoch_start_time = time.time()\n",
        "        net.train()\n",
        "        loss = train(train_dataloader, epoch)\n",
        "\n",
        "        net.eval()\n",
        "        valid_loss, acc = valid(valid_dataloader, epoch)\n",
        "        print(\"end of the epoch in %f seconds\" % (time.time() - epoch_start_time))\n",
        "        scheduler.step()\n",
        "        \n",
        "        train_losses.append(loss)\n",
        "        valid_losses.append(valid_loss)\n",
        "        valid_accuracy.append(acc)\n",
        "\n",
        "        torch.save(net.state_dict(), '/content/drive/Shareddrives/예림 하이/transformer-action-detect.pth')\n",
        "\n",
        "    print('[Best epoch: %d]' % valid_best['epoch'])\n",
        "    print('Accuracy of %5s: %.2f %%' % ('total', valid_best['total_acc']))\n",
        "    print('Done')\n",
        "\n",
        "    net.eval()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze9YL-bFo17S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3airCy261sVi"
      },
      "source": [
        "# import os\n",
        "# import json\n",
        "# import numpy as np\n",
        "\n",
        "# def getJsonData(json_file):\n",
        "#     with open(json_file, \"r\") as f:\n",
        "#         data = json.load(f)\n",
        "#     return data\n",
        "\n",
        "# def getVideoData(data,video_name):\n",
        "  \n",
        "#     \"\"\"\n",
        "#     data format -> { \"data\": [ { \"frame_index\": int,\n",
        "#                                  \"skeleton\": [{\n",
        "#                                                 \"pose\": [x1, y1, x2, y2, ... ],\n",
        "#                                                 \"score\": [1,1,1,...]\n",
        "#                                              }]\n",
        "#                                 },\n",
        "#                                 { \"frame_index\": int,\n",
        "#                                  \"skeleton\": [{\n",
        "#                                                 \"pose\": [x1, y1, x2, y2, ... ],\n",
        "#                                                 \"score\": [1,1,1,...]\n",
        "#                                              }]\n",
        "#                                 }, ...\n",
        "#                             ]\n",
        "#                      \"label\": str               # action\n",
        "#                      \"label_index\":  int        # unique data index (not sure)\n",
        "#                      }\n",
        "#     \"\"\"\n",
        "  \n",
        "#     video = data.get(video_name, None)\n",
        "#     if video is None:\n",
        "#         raise FileNotFoundError\n",
        "\n",
        "#     # first category\n",
        "#     vid_data = video['data']                # data contains frame_idx, skeleton(pose, score)\n",
        "#     vid_label = video['label']              # action\n",
        "#     vid_label_index = video['label_index']  # unique index\n",
        "\n",
        "#     # init numpy array\n",
        "#     pose_np = []\n",
        "#     angle_list = []\n",
        "\n",
        "#     # data category #frame 어떻게 자를지 결정하기\n",
        "#     for frame in vid_data:\n",
        "#         frame_idx = frame['frame_index']\n",
        "#         skeleton = frame['skeleton']\n",
        "#         pose = skeleton[0]['pose']\n",
        "\n",
        "\n",
        "#         start_point = list()\n",
        "#         mid_point = list()\n",
        "#         end_point = list()\n",
        "        \n",
        "\n",
        "#         #6, 8, 10\n",
        "#         if pose[11] != 0 :        \n",
        "#           start_point.append(pose[11])\n",
        "#           start_point.append(pose[12])\n",
        "#         if pose[15] != 0 :\n",
        "#           mid_point.append(pose[15])\n",
        "#           mid_point.append(pose[16])\n",
        "#         if pose[19] != 0 :\n",
        "#           end_point.append(pose[19])\n",
        "#           end_point.append(pose[20])\n",
        "\n",
        "        \n",
        "#         angle = getAngle(start_point, mid_point, end_point)\n",
        "#         angle_list.append(angle)\n",
        "\n",
        "#         score = skeleton[0]['score']\n",
        "\n",
        "#         pose_np.append(_getPose(pose))\n",
        "\n",
        "#     pose_np = np.array(pose_np)\n",
        "#     print(\"angle : \" + angle + \"label : \" + vid_label)\n",
        "#     print(size(pose_np))\n",
        "#     return angle_list, vid_label\n",
        "\n",
        "# def _getPose(pose):\n",
        "#     pose_reshape = []\n",
        "#     for i, p in enumerate(pose):\n",
        "#         if i % 2 == 1:\n",
        "#             pos = [pose[i-1], pose[i]]\n",
        "#             pose_reshape.append(pos)\n",
        "#     return pose_reshape\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     data = getJsonData(\"/content/label_1.json\")\n",
        "    \n",
        "#     graph, label = getVideoData(data, \"20201117_dog-walkrun-002803.mp4\") #data 형식을 바꾸던지, data name별로 text에 저장하던디 해야할듯\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}